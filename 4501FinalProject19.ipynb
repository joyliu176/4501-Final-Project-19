{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ce6f89c",
   "metadata": {},
   "source": [
    "<center><h1><b>NYC Apartment Search</b></h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a5a4e6",
   "metadata": {},
   "source": [
    "---\n",
    "# Setup\n",
    "\n",
    "## Import Statements\n",
    "\n",
    "This code block includes various import statements that bring in libraries and modules necessary for data manipulation, visualization, database operations, and geographic information system (GIS) tasks. These imports cover a wide range of functionalities required for the project.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1a5f05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "import json\n",
    "import unittest\n",
    "import pathlib\n",
    "import urllib.parse\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "\n",
    "# Data manipulation and visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import pandas as pd\n",
    "import requests\n",
    "import logging\n",
    "\n",
    "# Database and GIS related imports\n",
    "import psycopg2\n",
    "import psycopg2.extras\n",
    "import geoalchemy2 as gdb\n",
    "import geopandas as gpd\n",
    "import shapely\n",
    "from shapely.geometry import Point, Polygon, mapping\n",
    "from shapely import wkb\n",
    "\n",
    "# SQLAlchemy imports\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy import (\n",
    "    create_engine,\n",
    "    Column,\n",
    "    Integer,\n",
    "    Float,\n",
    "    String,\n",
    "    DateTime,\n",
    "    text,\n",
    "    ForeignKey,\n",
    ")\n",
    "from sqlalchemy.orm import sessionmaker, relationship\n",
    "from sqlalchemy.schema import CreateTable\n",
    "from geoalchemy2 import Geometry\n",
    "from geoalchemy2.shape import to_shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57bcaa2c",
   "metadata": {},
   "source": [
    "## Constants and File Paths\n",
    "\n",
    "This code block defines several constants and file paths for data directories and files related to the project. It also includes constants for accessing New York City data through an API.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a551e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths and directory constants\n",
    "DATA_DIR = pathlib.Path(\"data\")\n",
    "ZIPCODE_DATA_FILE = DATA_DIR / \"zipcodes\" / \"nyc_zipcodes.shp\"\n",
    "ZILLOW_DATA_FILE = DATA_DIR / \"zillow_rent_data.csv\"\n",
    "\n",
    "# New York City data API constants\n",
    "NYC_DATA_APP_TOKEN = \"SMg9akfNT3gV1L4QAEb8vlx4F\"\n",
    "BASE_NYC_DATA_URL = \"https://data.cityofnewyork.us/\"\n",
    "NYC_DATA_311 = \"erm2-nwe9.geojson\"\n",
    "NYC_DATA_TREES = \"5rq2-4hqu.geojson\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c78f3188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database constants\n",
    "DB_NAME = \"group19project\"\n",
    "DB_USER = \"cecilialin\"\n",
    "DB_URL = f\"postgres+psycopg2://{DB_USER}@localhost/{DB_NAME}\"\n",
    "DB_SCHEMA_FILE = \"schema.sql\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67ad14f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory for DB queries for Part 3\n",
    "QUERY_DIR = pathlib.Path(\"queries\")\n",
    "\n",
    "# Make sure the QUERY_DIRECTORY exists\n",
    "if not QUERY_DIR.exists():\n",
    "    QUERY_DIR.mkdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db4ed075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory data/resource has been created.\n"
     ]
    }
   ],
   "source": [
    "# Directory path\n",
    "directory = \"data/resource\"\n",
    "\n",
    "# Create the directory. exist_ok=True means it won't throw an error if the directory already exists.\n",
    "os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "print(f\"Directory {directory} has been created.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0baf20f",
   "metadata": {},
   "source": [
    "## Logging Setup\n",
    "\n",
    "This code block sets up logging for information (INFO) and error tracking. It configures the logging module to handle log messages for the current module.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb2572ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup logging for info and error tracking\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c8af43",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 1: Data Preprocessing\n",
    "\n",
    "In Part 1 of the project, the primary focus is on data preprocessing. This stage involves downloading datasets, both manually and programmatically, cleaning and filtering the data, filling in missing values, and generating relevant data samples. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468b099b",
   "metadata": {},
   "source": [
    "## New York City GeoJSON Data Downloading\n",
    "\n",
    "This function downloads New York City GeoJSON data in batches and saves them to individual files. Key features include:\n",
    "\n",
    "- **Batch Downloading**: Downloads data in manageable batches, controlled by the `limit` parameter.\n",
    "- **File Saving**: Each batch is saved as a separate GeoJSON file for efficient data handling.\n",
    "- **Error Handling and Logging**: Incorporates error handling for robust data retrieval and logs progress for tracking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6f6df2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_nyc_geojson_data(url: str, limit: int = 1000000) -> List[pathlib.Path]:\n",
    "    \"\"\"\n",
    "    Downloads NYC GeoJSON data in batches and saves each batch to a separate file.\n",
    "\n",
    "    :param url: URL to download the data from.\n",
    "    :param limit: Number of records per batch to download (default is 1,000,000).\n",
    "    :return: List of file paths of the downloaded GeoJSON files.\n",
    "    \"\"\"\n",
    "    \n",
    "    parsed_url = urllib.parse.urlparse(url)\n",
    "    url_path = parsed_url.path.strip(\"/\")\n",
    "    total_record_count = 0\n",
    "    file_index = 0\n",
    "    more_data_available = True\n",
    "\n",
    "    while more_data_available:\n",
    "        current_filename = DATA_DIR / f\"{url_path}_{file_index}.geojson\"\n",
    "        if not current_filename.exists():\n",
    "            logger.info(f\"Downloading data to {current_filename}...\")\n",
    "            try:\n",
    "                params = {'$limit': limit, '$offset': file_index * limit}\n",
    "                response = requests.get(url, params=params)\n",
    "                response.raise_for_status()\n",
    "                data = response.json()\n",
    "                if data:\n",
    "                    with open(current_filename, \"w\") as f:\n",
    "                        json.dump(data, f)\n",
    "                    total_record_count += len(data)\n",
    "\n",
    "                    # Check if the returned data is less than the requested limit\n",
    "                    if len(data) < limit:\n",
    "                        more_data_available = False\n",
    "                    else:\n",
    "                        file_index += 1\n",
    "\n",
    "                else:\n",
    "                    more_data_available = False\n",
    "            except requests.RequestException as e:\n",
    "                logger.error(f\"Failed to retrieve data: {e}\")\n",
    "                break\n",
    "        else:\n",
    "            logger.info(f\"File {current_filename} already exists. Skipping download.\")\n",
    "            file_index += 1\n",
    "\n",
    "    logger.info(f\"Total records downloaded: {total_record_count}\")\n",
    "    return [DATA_DIR / f\"{url_path}_{i}.geojson\" for i in range(file_index)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7cda25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
